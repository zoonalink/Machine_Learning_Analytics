{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling (Pseudo Plan)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Splitting\n",
    "* Split into training and test\n",
    "    * Train:\n",
    "        * More detailed EDA (maybe - so no bias introduced)\n",
    "        * Training models\n",
    "        * Hyperparameter tuning with cross-validation\n",
    "\n",
    "2. Data Scaling\n",
    "* In order to take out effect of different scales (e.g. number of clicks v dates)\n",
    "* Applied to Train and then use same paramaters on Test (to avoid data leakage)\n",
    "\n",
    "3. Unsupervised Clustering / EDA (optional - to consider)\n",
    "* Explore student profiles through unsupervised clustering\n",
    "* K-means clustering, hierarchical clustering\n",
    "\n",
    "4. Supervised Prediction Model:\n",
    "* Predict student outcome (`final_result`) - so classifier, classfication models\n",
    "    * E.g. Random Forest, Decision Trees, Support Vector Machines, Naive Bayes\n",
    "* Prepare feature matrix:\n",
    "    * Consider feature reduction, selection\n",
    "    * Encode categorical variables - one-hot encoding, label encoding\n",
    "\n",
    "5. Feature Selection / Dimensionality Reduction (optional)\n",
    "* Consider reducing/simplifying features by selection or dimensionality reduction\n",
    "* Correlation analysis, mutual information, feature importance (trees and forests?) \n",
    "* Consider PCA, LDA\n",
    "\n",
    "6. Model Training and Evaluation: \n",
    "* Train model\n",
    "* Evaluate model - metrics like accuracy, precision, recall, F1, AUC-ROC\n",
    "* Compare and select\n",
    "\n",
    "7. Variable Effects questions:\n",
    "* Signficance of different variables or categories of variables (bio, demo, study, behaviour) on prediction\n",
    "\n",
    "8. Performance over time\n",
    "* Accuracy (of model) overtime - different prediction points to compare performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset\n",
    "\n",
    "I decided to split the dataset into three -  `train` and `test` on a 75/25 split with stratification to ensure that the proportions remain the same within each subset.\n",
    "\n",
    "* `train` - model training, hyperparameter tuning with k-fold cross validation\n",
    "* `test` - final model evaluation, remains unseen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed data from csv file\n",
    "model = pd.read_csv('../data/final_model_ALL_20230525.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# drop 'id_student' column\n",
    "model = model.drop('id_student', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31437 entries, 0 to 31436\n",
      "Data columns (total 25 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   code_module              31437 non-null  object \n",
      " 1   code_presentation        31437 non-null  object \n",
      " 2   gender                   31437 non-null  object \n",
      " 3   region                   31437 non-null  object \n",
      " 4   highest_education        31437 non-null  object \n",
      " 5   imd_band                 31437 non-null  object \n",
      " 6   age_band                 31437 non-null  object \n",
      " 7   num_of_prev_attempts     31437 non-null  int64  \n",
      " 8   studied_credits          31437 non-null  int64  \n",
      " 9   disability               31437 non-null  object \n",
      " 10  course_length            31437 non-null  int64  \n",
      " 11  date_registration        31437 non-null  float64\n",
      " 12  date_unregistration      31437 non-null  float64\n",
      " 13  prop_submissions         31437 non-null  float64\n",
      " 14  avg_score                31437 non-null  float64\n",
      " 15  submission_distance      31437 non-null  float64\n",
      " 16  stu_activity_count       31437 non-null  float64\n",
      " 17  stu_activity_type_count  31437 non-null  float64\n",
      " 18  stu_total_clicks         31437 non-null  float64\n",
      " 19  stu_days_active          31437 non-null  float64\n",
      " 20  mod_pres_vle_type_count  31437 non-null  float64\n",
      " 21  year                     31437 non-null  object \n",
      " 22  month                    31437 non-null  object \n",
      " 23  subject                  31437 non-null  object \n",
      " 24  final_result             31437 non-null  object \n",
      "dtypes: float64(10), int64(3), object(12)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# drop 'status' - should have been dropped in function (now fixed)\n",
    "#model = model.drop('status', axis=1)\n",
    "\n",
    "#change year to str (object) - not fixed in function\n",
    "model['year'] = model['year'].astype(str)\n",
    "\n",
    "\n",
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# drop target from X, save target to y\n",
    "X = model.drop('final_result', axis=1)  \n",
    "y = model['final_result']  \n",
    "\n",
    "# split data into train and test sets with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=567)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check proportions - stratification\n",
    "\n",
    "It works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Proportions:\n",
      "Pass           0.376276\n",
      "Withdrawn      0.314311\n",
      "Fail           0.219550\n",
      "Distinction    0.089862\n",
      "Name: final_result, dtype: float64\n",
      "\n",
      "Train Set Proportions:\n",
      "Pass           0.376277\n",
      "Withdrawn      0.314327\n",
      "Fail           0.219532\n",
      "Distinction    0.089864\n",
      "Name: final_result, dtype: float64\n",
      "\n",
      "Test Set Proportions:\n",
      "Pass           0.376272\n",
      "Withdrawn      0.314249\n",
      "Fail           0.219625\n",
      "Distinction    0.089854\n",
      "Name: final_result, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# proportions of target variable in original data\n",
    "original_proportions = model['final_result'].value_counts(normalize=True)\n",
    "\n",
    "# proportions of target variable in train and test sets\n",
    "train_proportions = y_train.value_counts(normalize=True)\n",
    "test_proportions = y_test.value_counts(normalize=True)\n",
    "\n",
    "# results\n",
    "print(\"Original Proportions:\")\n",
    "print(original_proportions)\n",
    "\n",
    "print(\"\\nTrain Set Proportions:\")\n",
    "print(train_proportions)\n",
    "\n",
    "print(\"\\nTest Set Proportions:\")\n",
    "print(test_proportions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_module</th>\n",
       "      <th>code_presentation</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>highest_education</th>\n",
       "      <th>imd_band</th>\n",
       "      <th>age_band</th>\n",
       "      <th>num_of_prev_attempts</th>\n",
       "      <th>studied_credits</th>\n",
       "      <th>disability</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>submission_distance</th>\n",
       "      <th>stu_activity_count</th>\n",
       "      <th>stu_activity_type_count</th>\n",
       "      <th>stu_total_clicks</th>\n",
       "      <th>stu_days_active</th>\n",
       "      <th>mod_pres_vle_type_count</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [code_module, code_presentation, gender, region, highest_education, imd_band, age_band, num_of_prev_attempts, studied_credits, disability, course_length, date_registration, date_unregistration, prop_submissions, avg_score, submission_distance, stu_activity_count, stu_activity_type_count, stu_total_clicks, stu_days_active, mod_pres_vle_type_count, year, month, subject]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in X_train_transformed\n",
    "missing_values = X_train.isnull().sum()\n",
    "\n",
    "# Filter rows with missing values\n",
    "rows_with_missing = X_train[X_train.isnull().any(axis=1)]\n",
    "\n",
    "# Save the rows with missing values to a separate DataFrame or file\n",
    "rows_with_missing\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable preparation\n",
    "### Scaling and One-Hot Encoding / Ordinal\n",
    "\n",
    "Because the variables are in different units and scales - i.e. average score (0-100) v number_of_clicks (000s), the dataset needs to be scaled/normalised.  The `train` dataset is scaled and the same transformation (i.e. the same parameters) are applied to the `test` set.  This way there is no 'data leakage' - we have not accessed `test` in any way.\n",
    "\n",
    "Scaling only applies to 'numeric' variables - that is variables which can be, for example, means-centred (which is what I apply below).\n",
    "\n",
    "Categorical variables need to be excluded from this process, but they also require transformation.\n",
    "\n",
    "* One-hot encoding - converts categorical variables into binary vectors.  That is - it creates new binary columns for each category.  For example, module_code will have 'AAA' (Y/N) 'BBB' (Y/N) etc. for each row - where only one of the 7 columns will be a Y.  One-hot encoding is used where there is no inherent ordinal relationship between the categories.  For example, module 'AAA' cannot be ranked above or below module 'CCC'. \n",
    "\n",
    "* Ordinal encoding - is used for categorical variables which have an inherent ordinal structure, i.e. a meaningful order.  For example, 'age_band' can be ordered from lower ages to higher ages, as can 'highest_education' etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Columns:\n",
      "['num_of_prev_attempts', 'studied_credits', 'course_length', 'date_registration', 'date_unregistration', 'prop_submissions', 'avg_score', 'submission_distance', 'stu_activity_count', 'stu_activity_type_count', 'stu_total_clicks', 'stu_days_active', 'mod_pres_vle_type_count']\n",
      "\n",
      "\n",
      "Non-Numeric Columns:\n",
      "['code_module', 'code_presentation', 'gender', 'region', 'highest_education', 'imd_band', 'age_band', 'disability', 'year', 'month', 'subject']\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "non_numeric_columns = X_train.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(\"Numeric Columns:\")\n",
    "print(numeric_columns)\n",
    "print(\"\\n\")\n",
    "print(\"Non-Numeric Columns:\")\n",
    "print(non_numeric_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['55<=', '35-55', '0-35'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model['highest_education'].unique()\n",
    "#model['imd_band'].unique()\n",
    "#model['age_band'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_train.isnull().sum())\n",
    "#print(X_test.isnull().sum())\n",
    "\n",
    "#print(X_train.info())\n",
    "#print(X_test.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "\n",
    "# nominal and ordinal categorical columns\n",
    "nominal_cols = ['code_module', 'code_presentation', 'gender', 'region', 'disability', 'month', 'subject', 'year']\n",
    "ordinal_cols = ['highest_education', 'imd_band', 'age_band']\n",
    "\n",
    "# ordinal encoding for ordinal variables\n",
    "ordinal_mapping = {\n",
    "    'highest_education': {'No Formal quals': 0, 'Lower Than A Level': 1, 'A Level or Equivalent': 2, 'HE Qualification': 3, 'Post Graduate Qualification': 4},\n",
    "    'imd_band': {'0-10%': 0, '10-20': 1, '20-30%': 2, '30-40%': 3, '40-50%': 4, '50-60%': 5, '60-70%': 6, '70-80%': 7, '80-90%': 8, '90-100%': 9},  \n",
    "    'age_band': {'0-35': 0, '35-55': 1, '55<=': 2} \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# One-Hot Encoding\n",
    "X_train_nominal_encoded = pd.get_dummies(X_train[nominal_cols])\n",
    "X_test_nominal_encoded = pd.get_dummies(X_test[nominal_cols])\n",
    "\n",
    "#print(\"One-Hot Encoding:\")\n",
    "#print(X_train_nominal_encoded.info())\n",
    "#print(X_test_nominal_encoded.info())\n",
    "#print(\"X_train_nominal_encoded shape:\", X_train_nominal_encoded.shape)\n",
    "#print(\"X_test_nominal_encoded shape:\", X_test_nominal_encoded.shape)\n",
    "\n",
    "#print(\"\\n\") \n",
    "#print(X_train_nominal_encoded.isnull().sum())\n",
    "#print(X_test_nominal_encoded.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Encoding\n",
    "ordinal_encoder = OrdinalEncoder(categories=[list(ordinal_mapping[col].keys()) for col in ordinal_cols])\n",
    "X_train_ordinal_encoded = pd.DataFrame(ordinal_encoder.fit_transform(X_train[ordinal_cols]), columns=ordinal_cols)\n",
    "X_test_ordinal_encoded = pd.DataFrame(ordinal_encoder.transform(X_test[ordinal_cols]), columns=ordinal_cols)\n",
    "\n",
    "#print(\"Ordinal Encoding:\")\n",
    "#print(X_train_ordinal_encoded.info())\n",
    "#print(X_test_ordinal_encoded.info())\n",
    "#print(\"X_train_ordinal_encoded shape:\", X_train_ordinal_encoded.shape)\n",
    "#print(\"X_test_ordinal_encoded shape:\", X_test_ordinal_encoded.shape)\n",
    "\n",
    "#print(X_train_ordinal_encoded.isnull().sum())\n",
    "#print(X_test_ordinal_encoded.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_merged: (25149, 37)\n",
      "Shape of X_test_merged: (6288, 37)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reset the indices of ordinal and nominal encoded dataframes\n",
    "X_train_ordinal_encoded.reset_index(drop=True, inplace=True)\n",
    "X_train_nominal_encoded.reset_index(drop=True, inplace=True)\n",
    "X_test_ordinal_encoded.reset_index(drop=True, inplace=True)\n",
    "X_test_nominal_encoded.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Merge ordinal and nominal encoded dataframes using row indices\n",
    "X_train_merged = pd.concat([X_train_ordinal_encoded, X_train_nominal_encoded], axis=1)\n",
    "X_test_merged = pd.concat([X_test_ordinal_encoded, X_test_nominal_encoded], axis=1)\n",
    "\n",
    "# Verify the results of merging ordinal and nominal dataframes\n",
    "print(\"Shape of X_train_merged:\", X_train_merged.shape)\n",
    "print(\"Shape of X_test_merged:\", X_test_merged.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_transformed: (25149, 50)\n",
      "Shape of X_test_transformed: (6288, 50)\n"
     ]
    }
   ],
   "source": [
    "# standard Scaling\n",
    "X_train_numeric = X_train[numeric_columns]\n",
    "X_test_numeric = X_test[numeric_columns]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_numeric)\n",
    "X_test_scaled = scaler.transform(X_test_numeric)\n",
    "\n",
    "# reset the indices \n",
    "X_train_scaled_reset = pd.DataFrame(X_train_scaled, columns=numeric_columns).reset_index(drop=True)\n",
    "X_test_scaled_reset = pd.DataFrame(X_test_scaled, columns=numeric_columns).reset_index(drop=True)\n",
    "\n",
    "# concatenate merged ordinal and nominal dataframes with scaled dataframes\n",
    "X_train_transformed = pd.concat([X_train_merged, X_train_scaled_reset], axis=1)\n",
    "X_test_transformed = pd.concat([X_test_merged, X_test_scaled_reset], axis=1)\n",
    "\n",
    "# merging all dataframes\n",
    "print(\"Shape of X_train_transformed:\", X_train_transformed.shape)\n",
    "print(\"Shape of X_test_transformed:\", X_test_transformed.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Clustering / EDA\n",
    "\n",
    "First I will explore the data using unsupervised clustering.  This will help me to understand the data and the relationships between the variables.  It will also help me to understand the student profiles and whether there are any distinct groups of students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "biographical_cols = ['gender_F', 'gender_M', 'region_East Anglian Region', 'region_East Midlands Region', 'region_Ireland', 'region_London Region', 'region_North Region', 'region_North Western Region', 'region_Scotland', 'region_South East Region', 'region_South Region', 'region_South West Region', 'region_Wales', 'region_West Midlands Region', 'region_Yorkshire Region', 'disability_N', 'disability_Y', 'month_Feb', 'month_Oct', 'highest_education', 'imd_band', 'age_band']\n",
    "\n",
    "X_demographic = X_train_transformed[biographical_cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zoona\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# number of clusters\n",
    "n_clusters = 3\n",
    "\n",
    "# knn\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=567)\n",
    "\n",
    "# fit knn X_demographic dataset\n",
    "cluster_labels = kmeans.fit_predict(X_demographic)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

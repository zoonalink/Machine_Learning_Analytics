{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling (Pseudo Plan)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Splitting\n",
    "* Split into training and test\n",
    "    * Train:\n",
    "        * More detailed EDA (maybe - so no bias introduced)\n",
    "        * Training models\n",
    "        * Hyperparameter tuning with cross-validation\n",
    "\n",
    "2. Data Scaling\n",
    "* In order to take out effect of different scales (e.g. number of clicks v dates)\n",
    "* Applied to Train and then use same paramaters on Test (to avoid data leakage)\n",
    "\n",
    "3. Unsupervised Clustering / EDA (optional - to consider)\n",
    "* Explore student profiles through unsupervised clustering\n",
    "* K-means clustering, hierarchical clustering\n",
    "\n",
    "4. Supervised Prediction Model:\n",
    "* Predict student outcome (`final_result`) - so classifier, classfication models\n",
    "    * E.g. Random Forest, Decision Trees, Support Vector Machines, Naive Bayes\n",
    "* Prepare feature matrix:\n",
    "    * Consider feature reduction, selection\n",
    "    * Encode categorical variables - one-hot encoding, label encoding\n",
    "\n",
    "5. Feature Selection / Dimensionality Reduction (optional)\n",
    "* Consider reducing/simplifying features by selection or dimensionality reduction\n",
    "* Correlation analysis, mutual information, feature importance (trees and forests?) \n",
    "* Consider PCA, LDA\n",
    "\n",
    "6. Model Training and Evaluation: \n",
    "* Train model\n",
    "* Evaluate model - metrics like accuracy, precision, recall, F1, AUC-ROC\n",
    "* Compare and select\n",
    "\n",
    "7. Variable Effects questions:\n",
    "* Signficance of different variables or categories of variables (bio, demo, study, behaviour) on prediction\n",
    "\n",
    "8. Performance over time\n",
    "* Accuracy (of model) overtime - different prediction points to compare performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset\n",
    "\n",
    "I decided to split the dataset into three -  `train` and `test` on a 75/25 split with stratification to ensure that the proportions remain the same within each subset.\n",
    "\n",
    "* `train` - model training, hyperparameter tuning with k-fold cross validation\n",
    "* `test` - final model evaluation, remains unseen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed data from csv file\n",
    "model = pd.read_csv('../data/final_model_ALL_20230525.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# drop 'id_student' column\n",
    "model = model.drop('id_student', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31437 entries, 0 to 31436\n",
      "Data columns (total 25 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   code_module              31437 non-null  object \n",
      " 1   code_presentation        31437 non-null  object \n",
      " 2   gender                   31437 non-null  object \n",
      " 3   region                   31437 non-null  object \n",
      " 4   highest_education        31437 non-null  object \n",
      " 5   imd_band                 31437 non-null  object \n",
      " 6   age_band                 31437 non-null  object \n",
      " 7   num_of_prev_attempts     31437 non-null  int64  \n",
      " 8   studied_credits          31437 non-null  int64  \n",
      " 9   disability               31437 non-null  object \n",
      " 10  course_length            31437 non-null  int64  \n",
      " 11  date_registration        31437 non-null  float64\n",
      " 12  date_unregistration      31437 non-null  float64\n",
      " 13  prop_submissions         31437 non-null  float64\n",
      " 14  avg_score                31437 non-null  float64\n",
      " 15  submission_distance      31437 non-null  float64\n",
      " 16  stu_activity_count       31437 non-null  float64\n",
      " 17  stu_activity_type_count  31437 non-null  float64\n",
      " 18  stu_total_clicks         31437 non-null  float64\n",
      " 19  stu_days_active          31437 non-null  float64\n",
      " 20  mod_pres_vle_type_count  31437 non-null  float64\n",
      " 21  year                     31437 non-null  object \n",
      " 22  month                    31437 non-null  object \n",
      " 23  subject                  31437 non-null  object \n",
      " 24  final_result             31437 non-null  object \n",
      "dtypes: float64(10), int64(3), object(12)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# drop 'status' - should have been dropped in function (now fixed)\n",
    "#model = model.drop('status', axis=1)\n",
    "\n",
    "#change year to str (object) - not fixed in function\n",
    "model['year'] = model['year'].astype(str)\n",
    "\n",
    "\n",
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# drop target from X, save target to y\n",
    "X = model.drop('final_result', axis=1)  \n",
    "y = model['final_result']  \n",
    "\n",
    "# split data into train and test sets with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=567)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check proportions - stratification\n",
    "\n",
    "It works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Proportions:\n",
      "final_result\n",
      "Pass           0.376276\n",
      "Withdrawn      0.314311\n",
      "Fail           0.219550\n",
      "Distinction    0.089862\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Train Set Proportions:\n",
      "final_result\n",
      "Pass           0.376277\n",
      "Withdrawn      0.314327\n",
      "Fail           0.219532\n",
      "Distinction    0.089864\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test Set Proportions:\n",
      "final_result\n",
      "Pass           0.376272\n",
      "Withdrawn      0.314249\n",
      "Fail           0.219625\n",
      "Distinction    0.089854\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# proportions of target variable in original data\n",
    "original_proportions = model['final_result'].value_counts(normalize=True)\n",
    "\n",
    "# proportions of target variable in train and test sets\n",
    "train_proportions = y_train.value_counts(normalize=True)\n",
    "test_proportions = y_test.value_counts(normalize=True)\n",
    "\n",
    "# results\n",
    "print(\"Original Proportions:\")\n",
    "print(original_proportions)\n",
    "\n",
    "print(\"\\nTrain Set Proportions:\")\n",
    "print(train_proportions)\n",
    "\n",
    "print(\"\\nTest Set Proportions:\")\n",
    "print(test_proportions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_module</th>\n",
       "      <th>code_presentation</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>highest_education</th>\n",
       "      <th>imd_band</th>\n",
       "      <th>age_band</th>\n",
       "      <th>num_of_prev_attempts</th>\n",
       "      <th>studied_credits</th>\n",
       "      <th>disability</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>submission_distance</th>\n",
       "      <th>stu_activity_count</th>\n",
       "      <th>stu_activity_type_count</th>\n",
       "      <th>stu_total_clicks</th>\n",
       "      <th>stu_days_active</th>\n",
       "      <th>mod_pres_vle_type_count</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [code_module, code_presentation, gender, region, highest_education, imd_band, age_band, num_of_prev_attempts, studied_credits, disability, course_length, date_registration, date_unregistration, prop_submissions, avg_score, submission_distance, stu_activity_count, stu_activity_type_count, stu_total_clicks, stu_days_active, mod_pres_vle_type_count, year, month, subject]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in X_train_transformed\n",
    "missing_values = X_train.isnull().sum()\n",
    "\n",
    "# Filter rows with missing values\n",
    "rows_with_missing = X_train[X_train.isnull().any(axis=1)]\n",
    "\n",
    "# Save the rows with missing values to a separate DataFrame or file\n",
    "rows_with_missing\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable preparation\n",
    "### Scaling and One-Hot Encoding / Ordinal\n",
    "\n",
    "Because the variables are in different units and scales - i.e. average score (0-100) v number_of_clicks (000s), the dataset needs to be scaled/normalised.  The `train` dataset is scaled and the same transformation (i.e. the same parameters) are applied to the `test` set.  This way there is no 'data leakage' - we have not accessed `test` in any way.\n",
    "\n",
    "Scaling only applies to 'numeric' variables - that is variables which can be, for example, means-centred (which is what I apply below).\n",
    "\n",
    "Categorical variables need to be excluded from this process, but they also require transformation.\n",
    "\n",
    "* One-hot encoding - converts categorical variables into binary vectors.  That is - it creates new binary columns for each category.  For example, module_code will have 'AAA' (Y/N) 'BBB' (Y/N) etc. for each row - where only one of the 7 columns will be a Y.  One-hot encoding is used where there is no inherent ordinal relationship between the categories.  For example, module 'AAA' cannot be ranked above or below module 'CCC'. \n",
    "\n",
    "* Ordinal encoding - is used for categorical variables which have an inherent ordinal structure, i.e. a meaningful order.  For example, 'age_band' can be ordered from lower ages to higher ages, as can 'highest_education' etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Columns:\n",
      "['num_of_prev_attempts', 'studied_credits', 'course_length', 'date_registration', 'date_unregistration', 'prop_submissions', 'avg_score', 'submission_distance', 'stu_activity_count', 'stu_activity_type_count', 'stu_total_clicks', 'stu_days_active', 'mod_pres_vle_type_count']\n",
      "\n",
      "\n",
      "Non-Numeric Columns:\n",
      "['code_module', 'code_presentation', 'gender', 'region', 'highest_education', 'imd_band', 'age_band', 'disability', 'year', 'month', 'subject']\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "non_numeric_columns = X_train.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(\"Numeric Columns:\")\n",
    "print(numeric_columns)\n",
    "print(\"\\n\")\n",
    "print(\"Non-Numeric Columns:\")\n",
    "print(non_numeric_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model['highest_education'].unique()\n",
    "#model['imd_band'].unique()\n",
    "#model['age_band'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_train.isnull().sum())\n",
    "#print(X_test.isnull().sum())\n",
    "\n",
    "#print(X_train.info())\n",
    "#print(X_test.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "\n",
    "# nominal and ordinal categorical columns\n",
    "nominal_cols = ['code_module', 'code_presentation', 'gender', 'region', 'disability', 'month', 'subject', 'year']\n",
    "ordinal_cols = ['highest_education', 'imd_band', 'age_band']\n",
    "\n",
    "# ordinal encoding for ordinal variables\n",
    "ordinal_mapping = {\n",
    "    'highest_education': {'No Formal quals': 0, 'Lower Than A Level': 1, 'A Level or Equivalent': 2, 'HE Qualification': 3, 'Post Graduate Qualification': 4},\n",
    "    'imd_band': {'0-10%': 0, '10-20': 1, '20-30%': 2, '30-40%': 3, '40-50%': 4, '50-60%': 5, '60-70%': 6, '70-80%': 7, '80-90%': 8, '90-100%': 9},  \n",
    "    'age_band': {'0-35': 0, '35-55': 1, '55<=': 2} \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# One-Hot Encoding\n",
    "X_train_nominal_encoded = pd.get_dummies(X_train[nominal_cols])\n",
    "X_test_nominal_encoded = pd.get_dummies(X_test[nominal_cols])\n",
    "\n",
    "#print(\"One-Hot Encoding:\")\n",
    "#print(X_train_nominal_encoded.info())\n",
    "#print(X_test_nominal_encoded.info())\n",
    "#print(\"X_train_nominal_encoded shape:\", X_train_nominal_encoded.shape)\n",
    "#print(\"X_test_nominal_encoded shape:\", X_test_nominal_encoded.shape)\n",
    "\n",
    "#print(\"\\n\") \n",
    "#print(X_train_nominal_encoded.isnull().sum())\n",
    "#print(X_test_nominal_encoded.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Encoding\n",
    "ordinal_encoder = OrdinalEncoder(categories=[list(ordinal_mapping[col].keys()) for col in ordinal_cols])\n",
    "X_train_ordinal_encoded = pd.DataFrame(ordinal_encoder.fit_transform(X_train[ordinal_cols]), columns=ordinal_cols)\n",
    "X_test_ordinal_encoded = pd.DataFrame(ordinal_encoder.transform(X_test[ordinal_cols]), columns=ordinal_cols)\n",
    "\n",
    "#print(\"Ordinal Encoding:\")\n",
    "#print(X_train_ordinal_encoded.info())\n",
    "#print(X_test_ordinal_encoded.info())\n",
    "#print(\"X_train_ordinal_encoded shape:\", X_train_ordinal_encoded.shape)\n",
    "#print(\"X_test_ordinal_encoded shape:\", X_test_ordinal_encoded.shape)\n",
    "\n",
    "#print(X_train_ordinal_encoded.isnull().sum())\n",
    "#print(X_test_ordinal_encoded.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_merged: (25149, 37)\n",
      "Shape of X_test_merged: (6288, 37)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reset the indices of ordinal and nominal encoded dataframes\n",
    "X_train_ordinal_encoded.reset_index(drop=True, inplace=True)\n",
    "X_train_nominal_encoded.reset_index(drop=True, inplace=True)\n",
    "X_test_ordinal_encoded.reset_index(drop=True, inplace=True)\n",
    "X_test_nominal_encoded.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Merge ordinal and nominal encoded dataframes using row indices\n",
    "X_train_merged = pd.concat([X_train_ordinal_encoded, X_train_nominal_encoded], axis=1)\n",
    "X_test_merged = pd.concat([X_test_ordinal_encoded, X_test_nominal_encoded], axis=1)\n",
    "\n",
    "# Verify the results of merging ordinal and nominal dataframes\n",
    "print(\"Shape of X_train_merged:\", X_train_merged.shape)\n",
    "print(\"Shape of X_test_merged:\", X_test_merged.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_transformed: (25149, 50)\n",
      "Shape of X_test_transformed: (6288, 50)\n"
     ]
    }
   ],
   "source": [
    "# standard Scaling\n",
    "X_train_numeric = X_train[numeric_columns]\n",
    "X_test_numeric = X_test[numeric_columns]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_numeric)\n",
    "X_test_scaled = scaler.transform(X_test_numeric)\n",
    "\n",
    "# reset the indices \n",
    "X_train_scaled_reset = pd.DataFrame(X_train_scaled, columns=numeric_columns).reset_index(drop=True)\n",
    "X_test_scaled_reset = pd.DataFrame(X_test_scaled, columns=numeric_columns).reset_index(drop=True)\n",
    "\n",
    "# concatenate merged ordinal and nominal dataframes with scaled dataframes\n",
    "X_train_transformed = pd.concat([X_train_merged, X_train_scaled_reset], axis=1)\n",
    "X_test_transformed = pd.concat([X_test_merged, X_test_scaled_reset], axis=1)\n",
    "\n",
    "# merging all dataframes\n",
    "print(\"Shape of X_train_transformed:\", X_train_transformed.shape)\n",
    "print(\"Shape of X_test_transformed:\", X_test_transformed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed.to_csv('../data/X_train_transformed.csv', index=False)\n",
    "X_test_transformed.to_csv('../data/X_test_transformed.csv', index=False)\n",
    "y_train.to_csv('../data/y_train.csv', index=False)\n",
    "y_test.to_csv('../data/y_test.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

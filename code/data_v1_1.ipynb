{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "\n",
    "ou_zip = '../data/anonymisedData.zip'\n",
    "prediction_point = 200\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def process_OU(prediction_point):\n",
    "    # import zip file with csv\n",
    "    ou_zip = zipfile.ZipFile('../data/anonymisedData.zip')\n",
    "\n",
    "    # save separate csvs\n",
    "    registrations = pd.read_csv(ou_zip.open('studentRegistration.csv'))\n",
    "    courses = pd.read_csv(ou_zip.open('courses.csv'))\n",
    "    students = pd.read_csv(ou_zip.open('studentInfo.csv'))\n",
    "    student_vle = pd.read_csv(ou_zip.open('studentVle.csv'))\n",
    "    vle = pd.read_csv(ou_zip.open('vle.csv'))\n",
    "    student_assessments = pd.read_csv(ou_zip.open('studentAssessment.csv'))\n",
    "    assessments = pd.read_csv(ou_zip.open('assessments.csv'))\n",
    "\n",
    "    ## STUDENT REGISTRATIONS\n",
    "\n",
    "    # merge students and courses\n",
    "    student_regist = pd.merge(students, courses, on=['code_module', 'code_presentation'], validate='many_to_one')\n",
    "\n",
    "    # merge registrations\n",
    "    student_regist = pd.merge(student_regist, registrations, on=['code_module', 'code_presentation', 'id_student'], how='left', validate='1:1')\n",
    "\n",
    "    # drop missing value rows (date_registration, imd_band)\n",
    "    student_regist.dropna(subset=['date_registration', 'imd_band'], inplace=True)\n",
    "\n",
    "    # drop students who unregistered before registering\n",
    "    student_regist = student_regist[student_regist['date_unregistration'] < student_regist['date_registration']]\n",
    "\n",
    "    # prediction point must be less than course length, integer, and greater than 0\n",
    "    if not isinstance(prediction_point, int) or prediction_point <= 0 or prediction_point >= max(student_regist['module_presentation_length']):\n",
    "        print(\"Error: Invalid prediction point. \\n\\nPlease provide an integer value greater than 0 and less than the maximum course length. \\n\\nThis is the number of days from the start of the course for which you want to predict the outcome.\")\n",
    "    else:\n",
    "        # withdrawn or failed before prediction point - remove\n",
    "        withdrawn_fail_condition = (student_regist['final_result'].isin(['Withdrawn', 'Fail'])) & (student_regist['date_unregistration'] <= prediction_point)\n",
    "        student_regist.loc[withdrawn_fail_condition, 'status'] = 'remove_outcome_known'\n",
    "        # if unregister after prediction point - keep\n",
    "        unregister_after_condition = student_regist['date_unregistration'] > prediction_point\n",
    "        student_regist.loc[unregister_after_condition, 'status'] = 'keep'\n",
    "        # if no unregistration date - keep\n",
    "        no_unregistration_condition = student_regist['date_unregistration'].isna()\n",
    "        student_regist.loc[no_unregistration_condition, 'status'] = 'keep'\n",
    "        # default case\n",
    "        student_regist.loc[~(withdrawn_fail_condition | unregister_after_condition | no_unregistration_condition), 'status'] = 'query'\n",
    "\n",
    "    query_rows = student_regist[student_regist['status'] == 'query'] | student_regist[student_regist['status'].isna()]\n",
    "\n",
    "    if not query_rows.empty:\n",
    "        print(\"The following rows need investigation. They are excluded from the following analysis: \\n\")\n",
    "        print(query_rows)\n",
    "        final = student_regist[~student_regist.isin(query_rows)].dropna()\n",
    "\n",
    "    # replace missing date_unreg with module_presentation_length\n",
    "    student_regist['date_unregistration'] = student_regist['date_unregistration'].fillna(student_regist['module_presentation_length'])\n",
    "\n",
    "    # remove rows from final df which are not needed\n",
    "    model_final = student_regist[student_regist['status'] != 'remove_outcome_known']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return model_final.count()\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "\n",
    "prediction_point = 200\n",
    "result = process_OU(prediction_point)\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(zip_file):\n",
    "    '''Loads the data from the Open University Learning Analytics dataset zip file.'''\n",
    "\n",
    "    registrations = pd.read_csv(zip_file.open('studentRegistration.csv'))\n",
    "    courses = pd.read_csv(zip_file.open('courses.csv'))\n",
    "    students = pd.read_csv(zip_file.open('studentInfo.csv'))\n",
    "    student_vle = pd.read_csv(zip_file.open('studentVle.csv'))\n",
    "    vle = pd.read_csv(zip_file.open('vle.csv'))\n",
    "    student_assessments = pd.read_csv(zip_file.open('studentAssessment.csv'))\n",
    "    assessments = pd.read_csv(zip_file.open('assessments.csv'))\n",
    "    \n",
    "    return registrations, courses, students, student_vle, vle, student_assessments, assessments\n",
    "\n",
    "ou_zip = '../data/anonymisedData.zip'\n",
    "\n",
    "load_data(ou_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_data(students, courses, registrations, prediction_point=None):\n",
    "    '''Returns a dataframe of student data based on `students`: \n",
    "\n",
    "    prediction_point is an integer representing the number of days from the start of the course for which you want to predict the outcome.\n",
    "\n",
    "    default is max(student_regist['module_presentation_length']) - that is, the last da of the lengthiest course\n",
    "\n",
    "    - merge students and courses\n",
    "    - merge registrations\n",
    "    - drop missing value rows (date_registration, imd_band)\n",
    "    - drop students who unregistered before registering\n",
    "    - fills missing date_unregistration with module_presentation_length - that is, assumes they completed the course\n",
    "    - removes students who withdrew or failed before prediction point\n",
    "    '''\n",
    "\n",
    "    #prediction_point default\n",
    "    if prediction_point is None:\n",
    "        prediction_point = max(student_regist['module_presentation_length'])\n",
    "\n",
    "    # merge students and courses\n",
    "    student_regist = pd.merge(students, courses, on=['code_module', 'code_presentation'], validate='many_to_one')\n",
    "\n",
    "    # merge registrations\n",
    "    student_regist = pd.merge(student_regist, registrations, on=['code_module', 'code_presentation', 'id_student'], how = 'left', validate='1:1')\n",
    "\n",
    "    # drop missing value rows (date_registration, imd_band)\n",
    "    student_regist.dropna(subset=['date_registration', 'imd_band'], inplace=True)\n",
    "\n",
    "    # drop students who unregistered before registering\n",
    "    student_regist = student_regist[student_regist['date_unregistration'] < student_regist['date_registration']]\n",
    "\n",
    "\n",
    "    # drop students who unregistered before registering\n",
    "    student_regist = student_regist[student_regist['date_unregistration'] < student_regist['date_registration']]\n",
    "\n",
    "    # prediction point must be less than course length, integer, and greater than 0\n",
    "    if not isinstance(prediction_point, int) or prediction_point <= 0 or prediction_point >= max(student_regist['module_presentation_length']):\n",
    "        print(\"Error: Invalid prediction point. \\n\\nPlease provide an integer value greater than 0 and less than the maximum course length. \\n\\nThis is the number of days from the start of the course for which you want to predict the outcome.\")\n",
    "    else:\n",
    "        # withdrawn or failed before prediction point - remove\n",
    "        withdrawn_fail_condition = (student_regist['final_result'].isin(['Withdrawn', 'Fail'])) & (student_regist['date_unregistration'] <= prediction_point)\n",
    "        student_regist.loc[withdrawn_fail_condition, 'status'] = 'remove_outcome_known'\n",
    "        # if unregister after prediction point - keep\n",
    "        unregister_after_condition = student_regist['date_unregistration'] > prediction_point\n",
    "        student_regist.loc[unregister_after_condition, 'status'] = 'keep'\n",
    "        # if no unregistration date - keep\n",
    "        no_unregistration_condition = student_regist['date_unregistration'].isna()\n",
    "        student_regist.loc[no_unregistration_condition, 'status'] = 'keep'\n",
    "        # default case\n",
    "        student_regist.loc[~(withdrawn_fail_condition | unregister_after_condition | no_unregistration_condition), 'status'] = 'query'\n",
    "\n",
    "    # rows which need investigation\n",
    "    query_rows = student_regist[student_regist['status'] == 'query'] | student_regist[student_regist['status'].isna()]\n",
    "\n",
    "    # print rows which need investigation\n",
    "    if not query_rows.empty:\n",
    "        print(\"The following rows need investigation.  They are excluded from the following analysis: \\n\")\n",
    "        print(query_rows)\n",
    "        final = student_regist[~student_regist.isin(query_rows)].dropna()\n",
    "\n",
    "    # replace missing date_unreg with module_presentation_length\n",
    "    student_regist['date_unregistration'] = student_regist['date_unregistration'].fillna(student_regist['module_presentation_length'])\n",
    "\n",
    "    # remove rows from final student df which are not needed\n",
    "    model_final = student_regist[student_regist['status'] != 'remove_outcome_known']\n",
    "   \n",
    "\n",
    "    return model_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_assessments(student_assessments, assessments, courses, model_final, prediction_point=None):\n",
    "    '''Returns updated model_final dataframe with student assessment data added:\n",
    "\n",
    "    prediction_point is an integer representing the number of days from the start of the course for which you want to predict the outcome.\n",
    "\n",
    "    default is max(student_regist['module_presentation_length']) - that is, the last da of the lengthiest course\n",
    "\n",
    "    - merge 'assessments' and 'courses' and 'student_assessments'\n",
    "    - populate missing 'date' values with course final week - as suggested in literature\n",
    "    - remove students from 'model_final' who have no score for an assessment\n",
    "    - remove students with odd assessment dates (before registration, after unregistration, or very far into future)\n",
    "    - remove students who withdrew or failed before prediction point\n",
    "    - calculate new features - average score, submission date distance, proportion of assessments submitted\n",
    "    '''\n",
    "    # merge 'assessments' and 'courses' on 'code_module' and 'code_presentation'\n",
    "    course_assess = assessments.merge(courses[['code_module', 'code_presentation', 'module_presentation_length']], on=['code_module', 'code_presentation'], how='left')\n",
    "\n",
    "    # fill in the missing 'date' values with course final week (as per literature)\n",
    "    value_to_fill = course_assess['module_presentation_length'] - 3\n",
    "    course_assess['date'] = course_assess['date'].fillna(value_to_fill)\n",
    "\n",
    "    # merge student_assessments with course_assess\n",
    "    stu_assess = pd.merge(student_assessments, course_assess, on=['id_assessment'], how='left')\n",
    "\n",
    "    # drop students who have no score for an assessment\n",
    "    missing_score_rows = stu_assess[stu_assess['score'].isna()]\n",
    "\n",
    "    if not missing_score_rows.empty:\n",
    "        print(\"The following students have missing 'scores'. They are excluded from the following analysis: \\n\")\n",
    "        print(missing_score_rows)\n",
    "\n",
    "        # student ids with missing score\n",
    "        unique_ids_missing = missing_score_rows['id_student'].unique()\n",
    "\n",
    "        # remove students with missing score from model_final\n",
    "        model_final = model_final[~model_final['id_student'].isin(unique_ids_missing)]\n",
    "\n",
    "        # drop rows with missing score\n",
    "        stu_assess.dropna(subset=['score'], inplace=True)\n",
    "\n",
    "    # remove students with negative or extreme date_submitted values\n",
    "    max_module_length = stu_assess['module_presentation_length'].max()\n",
    "    greater_than_max_length = stu_assess[stu_assess['date_submitted'] > max_module_length]['id_student'].unique()\n",
    "    less_than_zero = stu_assess[stu_assess['date_submitted'] < 0]['id_student'].unique()\n",
    "    students_to_remove = set(greater_than_max_length) | set(less_than_zero)\n",
    "    model_final = model_final[~model_final['id_student'].isin(students_to_remove)]\n",
    "    stu_assess = stu_assess[~stu_assess['id_student'].isin(students_to_remove)]\n",
    "\n",
    "    # reduce data by prediction point\n",
    "    model_student_assess = stu_assess[stu_assess['date'] <= prediction_point]\n",
    "\n",
    "    # get expected assessment details\n",
    "    model_course_assess = course_assess[course_assess['date'] <= prediction_point]\n",
    "    expected_ass = model_course_assess.groupby(['code_module', 'code_presentation'])['id_assessment'].count().reset_index()\n",
    "    expected_ass = expected_ass.rename(columns={'id_assessment': 'exp_sub_count'})\n",
    "    date_sum = model_course_assess.groupby(['code_module', 'code_presentation'])['date'].sum().reset_index()\n",
    "    expected_ass = expected_ass.merge(date_sum, on=['code_module', 'code_presentation'], how='left')\n",
    "    expected_ass = expected_ass.rename(columns={'date': 'exp_sub_date_sum'})\n",
    "\n",
    "    # summarise students' assessments by module_presentation\n",
    "    student_assessment_summary = model_student_assess.groupby(['id_student', 'code_module', 'code_presentation']).agg(\n",
    "        count_id_assessment=('id_assessment', 'count'),\n",
    "        sum_score=('score', 'sum'),\n",
    "        sum_date=('date', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    # merge student_assessment_summary and expected_ass on code_module and code_presentation\n",
    "    merged_assess_summary = student_assessment_summary.merge(expected_ass, on=['code_module', 'code_presentation'])\n",
    "\n",
    "    # calculate the new features\n",
    "    merged_assess_summary['prop_submissions'] = merged_assess_summary['count_id_assessment'] / merged_assess_summary['exp_sub_count']\n",
    "    merged_assess_summary['avg_score'] = merged_assess_summary['sum_score'] / merged_assess_summary['exp_sub_count']\n",
    "    merged_assess_summary['submission_distance'] = merged_assess_summary['exp_sub_date_sum'] - merged_assess_summary['sum_date']\n",
    "\n",
    "    # merge with 'model_final'\n",
    "    model_final = model_final.merge(merged_assess_summary, on=['id_student', 'code_module', 'code_presentation'], how='inner')\n",
    "\n",
    "    return model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vle_data(model_final, student_vle, vle, courses, prediction_point=None):\n",
    "    '''Returns updated model_final dataframe with vle data:\n",
    "\n",
    "    prediction_point is an integer representing the number of days from the start of the course for which you want to predict the outcome.\n",
    "\n",
    "    default is max(student_regist['module_presentation_length']) - that is, the last da of the lengthiest course\n",
    "\n",
    "    - merge 'vle' and 'courses' and 'student_vle'\n",
    "    - remove columns (week_from, week_to)\n",
    "    - filter the rows where 'date' <= 'prediction_point'\n",
    "    - create new features: vle_activity_count, student vle type count, student total clicks, student days active (engaged)\n",
    "    \n",
    "    '''\n",
    "    # merge 'vle' and 'courses' on 'code_module' and 'code_presentation'\n",
    "    course_vle = vle.merge(courses, on=['code_module', 'code_presentation'], how='left').drop(['week_from', 'week_to'], axis=1)\n",
    "\n",
    "    # merge vle with student_vle\n",
    "    all_stu_vle = pd.merge(student_vle, course_vle, on=['id_site', 'code_module', 'code_presentation'], how='left')\n",
    "\n",
    "    # filter the rows where 'date' <= 'prediction_point'\n",
    "    all_stu_vle = all_stu_vle[all_stu_vle['date'] <= prediction_point]\n",
    "\n",
    "    # filter the rows where 'date' is greater than 'module_presentation_length'\n",
    "    vle_after_done = all_stu_vle[all_stu_vle['date'] > all_stu_vle['module_presentation_length']]\n",
    "\n",
    "    if not vle_after_done.empty:\n",
    "        print(\"The following rows need investigation. They are excluded from the following analysis: \\n\")\n",
    "        print(vle_after_done)\n",
    "\n",
    "        # match rows based on 'code_module', 'code_presentation', and 'id_student'\n",
    "        matching_rows = model_final[model_final[['code_module', 'code_presentation', 'id_student']].isin(vle_after_done).all(axis=1)]\n",
    "\n",
    "        # remove the matching rows from 'model_final'\n",
    "        model_final = model_final[~model_final.index.isin(matching_rows.index)]\n",
    "\n",
    "    # aggregations for each column\n",
    "    aggregations = {\n",
    "        'id_site': 'count',\n",
    "        'activity_type': 'nunique',\n",
    "        'sum_click': 'sum',\n",
    "        'date': lambda x: x.nunique()\n",
    "    }\n",
    "\n",
    "    # group and apply the aggregations\n",
    "    grouped_stu_vle = all_stu_vle.groupby(['code_module', 'code_presentation', 'id_student']).agg(aggregations).reset_index()\n",
    "\n",
    "    # rename the columns\n",
    "    grouped_stu_vle.rename(columns={\n",
    "        'id_site': 'stu_activity_count',\n",
    "        'activity_type': 'stu_activity_type_count',\n",
    "        'sum_click': 'stu_total_clicks',\n",
    "        'date': 'stu_days_active'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # number of vle types per module_presentation\n",
    "    group_vle = vle.groupby(['code_module', 'code_presentation'])['activity_type'].nunique().reset_index()\n",
    "    group_vle.rename(columns={'activity_type': 'mod_pres_vle_type_count'}, inplace=True)\n",
    "\n",
    "    # merge 'grouped_stu_vle' and 'group_vle' on 'code_module' and 'code_presentation'\n",
    "    merged_vle_summary = grouped_stu_vle.merge(group_vle, on=['code_module', 'code_presentation'], how='left')\n",
    "\n",
    "    # merge with 'model_final'\n",
    "    model_final = model_final.merge(merged_vle_summary, on=['id_student', 'code_module', 'code_presentation'], how='inner')\n",
    "\n",
    "    return model_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_up_model_final(model_final):\n",
    "    '''Returns updated model_final dataframe:\n",
    "    - deleted unnecessary columns\n",
    "    - reordered columns\n",
    "    - added subject, year, month columns\n",
    "    \n",
    "    '''\n",
    "    # new columns for module_presentation - subject, year, month\n",
    "    model_final['year'] = model_final['code_presentation'].str[:4].astype(int)\n",
    "    model_final['month'] = model_final['code_presentation'].str[-1].map({'J': 'Oct', 'B': 'Feb'})\n",
    "\n",
    "    # module subject mapping\n",
    "    code_module_mapping = {\n",
    "        'AAA': 'SocSci',\n",
    "        'BBB': 'SocSci',\n",
    "        'GGG': 'SocSci',\n",
    "        'CCC': 'Stem',\n",
    "        'DDD': 'Stem',\n",
    "        'EEE': 'Stem',\n",
    "        'FFF': 'Stem'\n",
    "    }\n",
    "    model_final['subject'] = model_final['code_module'].map(code_module_mapping)\n",
    "\n",
    "    # rename 'module_presentation_length' to 'course_length'\n",
    "    model_final.rename(columns={'module_presentation_length': 'course_length'}, inplace=True)\n",
    "\n",
    "    # combine 'code_module', 'code_presentation', and 'id_student' into 'mod_pres_stu'\n",
    "    model_final['mod_pres_stu'] = model_final['code_module'] + '-' + model_final['code_presentation'] + '-' + model_final['id_student'].astype(str)\n",
    "\n",
    "    # drop the separate columns 'code_module', 'code_presentation', and 'id_student'\n",
    "    model_final.drop(columns=['code_module', 'code_presentation', 'id_student'], inplace=True)\n",
    "\n",
    "    # move 'final_result' to the last column\n",
    "    final_result_column = model_final.pop('final_result')\n",
    "    model_final['final_result'] = final_result_column\n",
    "\n",
    "    # insert 'mod_pres_stu' as the first column\n",
    "    mod_pres_stu_column = model_final.pop('mod_pres_stu')\n",
    "    model_final.insert(0, 'mod_pres_stu', mod_pres_stu_column)\n",
    "\n",
    "    # drop columns: 'count_id_assessment', 'sum_score', 'sum_date', 'exp_sub_count', 'exp_sub_date_sum'\n",
    "    model_final.drop(columns=['count_id_assessment', 'sum_score', 'sum_date', 'exp_sub_count', 'exp_sub_date_sum'], inplace=True)\n",
    "\n",
    "    return model_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(zip_file, prediction_point=None):\n",
    "    # load data from the zip file\n",
    "    data = load_data(zip_file)\n",
    "    students, courses, registrations, student_vle, vle, student_assessments, assessments = data['students'], data['courses'], data['registrations'], data['student_vle'], data['vle'], data['student_assessments'], data['assessments']\n",
    "\n",
    "    # student data\n",
    "    model_final = student_data(students, courses, registrations, prediction_point)\n",
    "\n",
    "    # add assessments to model_final\n",
    "    model_final = add_assessments(model_final, student_assessments, assessments, courses, prediction_point)\n",
    "\n",
    "    # add VLE data to model_final\n",
    "    model_final = add_vle_data(model_final, student_vle, vle, courses, prediction_point)\n",
    "\n",
    "    # tidy up model_final\n",
    "    model_final = tidy_up_model_final(model_final)\n",
    "\n",
    "    return model_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add default for prediction point, ie. if none"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

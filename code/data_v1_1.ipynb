{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code in functions\n",
    "#super function not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "zipfile_ou = '../data/anonymisedData.zip'\n",
    "prediction_point = 200\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(zip_file_path):\n",
    "    '''Loads the data from the Open University Learning Analytics dataset zip file.'''\n",
    "    \n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_file:\n",
    "        registrations = pd.read_csv(zip_file.open('studentRegistration.csv'))\n",
    "        courses = pd.read_csv(zip_file.open('courses.csv'))\n",
    "        students = pd.read_csv(zip_file.open('studentInfo.csv'))\n",
    "        student_vle = pd.read_csv(zip_file.open('studentVle.csv'))\n",
    "        vle = pd.read_csv(zip_file.open('vle.csv'))\n",
    "        student_assessments = pd.read_csv(zip_file.open('studentAssessment.csv'))\n",
    "        assessments = pd.read_csv(zip_file.open('assessments.csv'))\n",
    "    \n",
    "    return registrations, courses, students, student_vle, vle, student_assessments, assessments\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "registrations, courses, students, student_vle, vle, student_assessments, assessments = load_data(zipfile_ou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assessments.info()\n",
    "#courses.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_data(students, courses, registrations, prediction_point=None):\n",
    "    '''Returns a dataframe of student data based on `students`: \n",
    "\n",
    "    prediction_point is an integer representing the number of days from the start of the course for which you want to predict the outcome.\n",
    "\n",
    "    default is max(student_regist['module_presentation_length']) - that is, the last da of the lengthiest course\n",
    "\n",
    "    - merge students and courses\n",
    "    - merge registrations\n",
    "    - drop missing value rows (date_registration, imd_band)\n",
    "    - drop students who unregistered before registering\n",
    "    - fills missing date_unregistration with module_presentation_length - that is, assumes they completed the course\n",
    "    - removes students who withdrew or failed before prediction point\n",
    "    '''\n",
    "\n",
    "    # merge students and courses\n",
    "    student_regist = pd.merge(students, courses, on=['code_module', 'code_presentation'], validate='many_to_one')\n",
    "\n",
    "    # merge registrations\n",
    "    student_regist = pd.merge(student_regist, registrations, on=['code_module', 'code_presentation', 'id_student'], how = 'left', validate='1:1')\n",
    "\n",
    "    #prediction_point default\n",
    "    if prediction_point is None:\n",
    "        prediction_point = max(student_regist['module_presentation_length']) \n",
    "\n",
    "    # drop missing value rows (date_registration, imd_band)\n",
    "    student_regist.dropna(subset=['date_registration', 'imd_band'], inplace=True)\n",
    "\n",
    "    # prediction point must be less than course length, integer, and greater than 0\n",
    "    if not isinstance(prediction_point, int) or prediction_point <= 0 or prediction_point >= max(student_regist['module_presentation_length']):\n",
    "        print(\"Error: Invalid prediction point. \\n\\nPlease provide an integer value greater than 0 and less than the maximum course length. \\n\\nThis is the number of days from the start of the course for which you want to predict the outcome.\")\n",
    "    else:\n",
    "        # withdrawn or failed before prediction point - remove\n",
    "        withdrawn_fail_condition = (student_regist['final_result'].isin(['Withdrawn', 'Fail'])) & (student_regist['date_unregistration'] <= prediction_point)\n",
    "        student_regist.loc[withdrawn_fail_condition, 'status'] = 'remove_outcome_known'\n",
    "        # if unregister after prediction point - keep\n",
    "        unregister_after_condition = student_regist['date_unregistration'] > prediction_point\n",
    "        student_regist.loc[unregister_after_condition, 'status'] = 'keep'\n",
    "        # if no unregistration date - keep\n",
    "        no_unregistration_condition = student_regist['date_unregistration'].isna()\n",
    "        student_regist.loc[no_unregistration_condition, 'status'] = 'keep'\n",
    "        # default case\n",
    "        student_regist.loc[~(withdrawn_fail_condition | unregister_after_condition | no_unregistration_condition), 'status'] = 'query'\n",
    "\n",
    "    # rows which need investigation\n",
    "    query_rows = student_regist[student_regist['status'] == 'query'] | student_regist[student_regist['status'].isna()]\n",
    "\n",
    "    # print rows which need investigation\n",
    "    if not query_rows.empty:\n",
    "        print(\"The following rows need investigation.  They are excluded from the following analysis: \\n\")\n",
    "        print(query_rows)\n",
    "        student_regist = student_regist[~student_regist.isin(query_rows)].dropna()\n",
    "\n",
    "    # replace missing date_unreg with module_presentation_length\n",
    "    student_regist['date_unregistration'] = student_regist['date_unregistration'].fillna(student_regist['module_presentation_length'])\n",
    "\n",
    "    # drop students who unregistered before registering\n",
    "    student_regist = student_regist[student_regist['date_unregistration'] >= student_regist['date_registration']]\n",
    "\n",
    "    # remove rows from final student df which are not needed\n",
    "    model_final = student_regist[student_regist['status'] != 'remove_outcome_known']\n",
    "   \n",
    "\n",
    "    return model_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = student_data(students, courses, registrations, prediction_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_assessments(student_assessments, assessments, courses, model_final, prediction_point=None):\n",
    "    '''Returns updated model_final dataframe with student assessment data added:\n",
    "\n",
    "    prediction_point is an integer representing the number of days from the start of the course for which you want to predict the outcome.\n",
    "\n",
    "    default is max(student_regist['module_presentation_length']) - that is, the last da of the lengthiest course\n",
    "\n",
    "    - merge 'assessments' and 'courses' and 'student_assessments'\n",
    "    - populate missing 'date' values with course final week - as suggested in literature\n",
    "    - remove students from 'model_final' who have no score for an assessment\n",
    "    - remove students with odd assessment dates (before registration, after unregistration, or very far into future)\n",
    "    - remove students who withdrew or failed before prediction point\n",
    "    - calculate new features - average score, submission date distance, proportion of assessments submitted\n",
    "    '''\n",
    "    # merge 'assessments' and 'courses' on 'code_module' and 'code_presentation'\n",
    "    course_assess = pd.merge(assessments,courses, on=['code_module', 'code_presentation'], how='left')\n",
    "\n",
    "    # fill in the missing 'date' values with course final week (as per literature)\n",
    "    value_to_fill = course_assess['module_presentation_length'] - 3\n",
    "    course_assess['date'] = course_assess['date'].fillna(value_to_fill)\n",
    "\n",
    "    # merge student_assessments with course_assess\n",
    "    stu_assess = pd.merge(student_assessments, course_assess, on=['id_assessment'], how='left')\n",
    "\n",
    "    # drop students who have no score for an assessment\n",
    "    missing_score_rows = stu_assess[stu_assess['score'].isna()]\n",
    "\n",
    "    if not missing_score_rows.empty:\n",
    "        print(\"\\n\\nThe following students have missing 'scores'. They are excluded from the analysis: \\n\")\n",
    "        print(missing_score_rows)\n",
    "\n",
    "        # student ids with missing score\n",
    "        unique_ids_missing = missing_score_rows['id_student'].unique()\n",
    "\n",
    "        # remove students with missing score from model_final\n",
    "        model_final = model_final[~model_final['id_student'].isin(unique_ids_missing)]\n",
    "\n",
    "        # drop rows with missing score\n",
    "        stu_assess.dropna(subset=['score'], inplace=True)\n",
    "\n",
    "    # remove students with negative or extreme date_submitted values\n",
    "    max_module_length = stu_assess['module_presentation_length'].max()\n",
    "    greater_than_max_length = stu_assess[stu_assess['date_submitted'] > max_module_length]['id_student'].unique()\n",
    "    less_than_zero = stu_assess[stu_assess['date_submitted'] < 0]['id_student'].unique()\n",
    "    students_to_remove = set(greater_than_max_length) | set(less_than_zero)\n",
    "    model_final = model_final[~model_final['id_student'].isin(students_to_remove)]\n",
    "    stu_assess = stu_assess[~stu_assess['id_student'].isin(students_to_remove)]\n",
    "\n",
    "    # reduce data by prediction point\n",
    "    model_student_assess = stu_assess[stu_assess['date'] <= prediction_point]\n",
    "\n",
    "    # get expected assessment details\n",
    "    model_course_assess = course_assess[course_assess['date'] <= prediction_point]\n",
    "    expected_ass = model_course_assess.groupby(['code_module', 'code_presentation'])['id_assessment'].count().reset_index()\n",
    "    expected_ass = expected_ass.rename(columns={'id_assessment': 'exp_sub_count'})\n",
    "    date_sum = model_course_assess.groupby(['code_module', 'code_presentation'])['date'].sum().reset_index()\n",
    "    expected_ass = expected_ass.merge(date_sum, on=['code_module', 'code_presentation'], how='left')\n",
    "    expected_ass = expected_ass.rename(columns={'date': 'exp_sub_date_sum'})\n",
    "\n",
    "    # summarise students' assessments by module_presentation\n",
    "    student_assessment_summary = model_student_assess.groupby(['id_student', 'code_module', 'code_presentation']).agg(\n",
    "        count_id_assessment=('id_assessment', 'count'),\n",
    "        sum_score=('score', 'sum'),\n",
    "        sum_date=('date', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    # merge student_assessment_summary and expected_ass on code_module and code_presentation\n",
    "    merged_assess_summary = student_assessment_summary.merge(expected_ass, on=['code_module', 'code_presentation'])\n",
    "\n",
    "    # calculate the new features\n",
    "    merged_assess_summary['prop_submissions'] = merged_assess_summary['count_id_assessment'] / merged_assess_summary['exp_sub_count']\n",
    "    merged_assess_summary['avg_score'] = merged_assess_summary['sum_score'] / merged_assess_summary['exp_sub_count']\n",
    "    merged_assess_summary['submission_distance'] = merged_assess_summary['exp_sub_date_sum'] - merged_assess_summary['sum_date']\n",
    "\n",
    "    # merge with 'model_final'\n",
    "    model_final = model_final.merge(merged_assess_summary, on=['id_student', 'code_module', 'code_presentation'], how='inner')\n",
    "\n",
    "    return model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The following students have missing 'scores'. They are excluded from the analysis: \n",
      "\n",
      "        id_assessment  id_student  date_submitted  is_banked  score  \\\n",
      "215              1752      721259              22          0    NaN   \n",
      "937              1754      260355             127          0    NaN   \n",
      "2364             1760     2606802             180          0    NaN   \n",
      "3358            14984      186780              77          0    NaN   \n",
      "3914            14984      531205              26          0    NaN   \n",
      "...               ...         ...             ...        ...    ...   \n",
      "148929          34903      582670             241          0    NaN   \n",
      "159251          37415      610738              87          0    NaN   \n",
      "166390          37427      631786             221          0    NaN   \n",
      "169725          37435      648110              62          0    NaN   \n",
      "170103          37435      480914              49          0    NaN   \n",
      "\n",
      "       code_module code_presentation assessment_type   date  weight  \\\n",
      "215            AAA             2013J             TMA   19.0    10.0   \n",
      "937            AAA             2013J             TMA  117.0    20.0   \n",
      "2364           AAA             2014J             TMA  117.0    20.0   \n",
      "3358           BBB             2013B             TMA   19.0     5.0   \n",
      "3914           BBB             2013B             TMA   19.0     5.0   \n",
      "...            ...               ...             ...    ...     ...   \n",
      "148929         FFF             2014J             TMA  199.0    25.0   \n",
      "159251         GGG             2013J             TMA   61.0     0.0   \n",
      "166390         GGG             2014B             TMA  166.0     0.0   \n",
      "169725         GGG             2014J             TMA   61.0     0.0   \n",
      "170103         GGG             2014J             TMA   61.0     0.0   \n",
      "\n",
      "        module_presentation_length  \n",
      "215                            268  \n",
      "937                            268  \n",
      "2364                           269  \n",
      "3358                           240  \n",
      "3914                           240  \n",
      "...                            ...  \n",
      "148929                         269  \n",
      "159251                         261  \n",
      "166390                         241  \n",
      "169725                         269  \n",
      "170103                         269  \n",
      "\n",
      "[173 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "model_final = add_assessments(student_assessments, assessments, courses, model_final, prediction_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code_module                   20073\n",
       "code_presentation             20073\n",
       "id_student                    20073\n",
       "gender                        20073\n",
       "region                        20073\n",
       "highest_education             20073\n",
       "imd_band                      20073\n",
       "age_band                      20073\n",
       "num_of_prev_attempts          20073\n",
       "studied_credits               20073\n",
       "disability                    20073\n",
       "final_result                  20073\n",
       "module_presentation_length    20073\n",
       "date_registration             20073\n",
       "date_unregistration           20073\n",
       "status                        20073\n",
       "count_id_assessment           20073\n",
       "sum_score                     20073\n",
       "sum_date                      20073\n",
       "exp_sub_count                 20073\n",
       "exp_sub_date_sum              20073\n",
       "prop_submissions              20073\n",
       "avg_score                     20073\n",
       "submission_distance           20073\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vle_data(model_final, student_vle, vle, courses, prediction_point=None):\n",
    "    '''Returns updated model_final dataframe with vle data:\n",
    "\n",
    "    prediction_point is an integer representing the number of days from the start of the course for which you want to predict the outcome.\n",
    "\n",
    "    default is max(student_regist['module_presentation_length']) - that is, the last da of the lengthiest course\n",
    "\n",
    "    - merge 'vle' and 'courses' and 'student_vle'\n",
    "    - remove columns (week_from, week_to)\n",
    "    - filter the rows where 'date' <= 'prediction_point'\n",
    "    - create new features: vle_activity_count, student vle type count, student total clicks, student days active (engaged)\n",
    "    \n",
    "    '''\n",
    "    # merge 'vle' and 'courses' on 'code_module' and 'code_presentation'\n",
    "    course_vle = vle.merge(courses, on=['code_module', 'code_presentation'], how='left').drop(['week_from', 'week_to'], axis=1)\n",
    "\n",
    "    # merge vle with student_vle\n",
    "    all_stu_vle = pd.merge(student_vle, course_vle, on=['id_site', 'code_module', 'code_presentation'], how='left')\n",
    "\n",
    "    # filter the rows where 'date' <= 'prediction_point'\n",
    "    all_stu_vle = all_stu_vle[all_stu_vle['date'] <= prediction_point]\n",
    "\n",
    "    # filter the rows where 'date' is greater than 'module_presentation_length'\n",
    "    vle_after_done = all_stu_vle[all_stu_vle['date'] > all_stu_vle['module_presentation_length']]\n",
    "\n",
    "    if not vle_after_done.empty:\n",
    "        print(\"The following rows need investigation. They are excluded from the following analysis: \\n\")\n",
    "        print(vle_after_done)\n",
    "\n",
    "        # match rows based on 'code_module', 'code_presentation', and 'id_student'\n",
    "        matching_rows = model_final[model_final[['code_module', 'code_presentation', 'id_student']].isin(vle_after_done).all(axis=1)]\n",
    "\n",
    "        # remove the matching rows from 'model_final'\n",
    "        model_final = model_final[~model_final.index.isin(matching_rows.index)]\n",
    "\n",
    "    # aggregations for each column\n",
    "    aggregations = {\n",
    "        'id_site': 'count',\n",
    "        'activity_type': 'nunique',\n",
    "        'sum_click': 'sum',\n",
    "        'date': lambda x: x.nunique()\n",
    "    }\n",
    "\n",
    "    # group and apply the aggregations\n",
    "    grouped_stu_vle = all_stu_vle.groupby(['code_module', 'code_presentation', 'id_student']).agg(aggregations).reset_index()\n",
    "\n",
    "    # rename the columns\n",
    "    grouped_stu_vle.rename(columns={\n",
    "        'id_site': 'stu_activity_count',\n",
    "        'activity_type': 'stu_activity_type_count',\n",
    "        'sum_click': 'stu_total_clicks',\n",
    "        'date': 'stu_days_active'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # number of vle types per module_presentation\n",
    "    group_vle = vle.groupby(['code_module', 'code_presentation'])['activity_type'].nunique().reset_index()\n",
    "    group_vle.rename(columns={'activity_type': 'mod_pres_vle_type_count'}, inplace=True)\n",
    "\n",
    "    # merge 'grouped_stu_vle' and 'group_vle' on 'code_module' and 'code_presentation'\n",
    "    merged_vle_summary = grouped_stu_vle.merge(group_vle, on=['code_module', 'code_presentation'], how='left')\n",
    "\n",
    "    # merge with 'model_final'\n",
    "    model_final = model_final.merge(merged_vle_summary, on=['id_student', 'code_module', 'code_presentation'], how='inner')\n",
    "\n",
    "    return model_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = add_vle_data(model_final, student_vle, vle, courses, prediction_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code_module                   20063\n",
       "code_presentation             20063\n",
       "id_student                    20063\n",
       "gender                        20063\n",
       "region                        20063\n",
       "highest_education             20063\n",
       "imd_band                      20063\n",
       "age_band                      20063\n",
       "num_of_prev_attempts          20063\n",
       "studied_credits               20063\n",
       "disability                    20063\n",
       "final_result                  20063\n",
       "module_presentation_length    20063\n",
       "date_registration             20063\n",
       "date_unregistration           20063\n",
       "status                        20063\n",
       "count_id_assessment           20063\n",
       "sum_score                     20063\n",
       "sum_date                      20063\n",
       "exp_sub_count                 20063\n",
       "exp_sub_date_sum              20063\n",
       "prop_submissions              20063\n",
       "avg_score                     20063\n",
       "submission_distance           20063\n",
       "stu_activity_count            20063\n",
       "stu_activity_type_count       20063\n",
       "stu_total_clicks              20063\n",
       "stu_days_active               20063\n",
       "mod_pres_vle_type_count       20063\n",
       "dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_up_model_final(model_final):\n",
    "    '''Returns updated model_final dataframe:\n",
    "    - deleted unnecessary columns\n",
    "    - reordered columns\n",
    "    - added subject, year, month columns\n",
    "    \n",
    "    '''\n",
    "    # new columns for module_presentation - subject, year, month\n",
    "    model_final['year'] = model_final['code_presentation'].str[:4].astype(int)\n",
    "    model_final['month'] = model_final['code_presentation'].str[-1].map({'J': 'Oct', 'B': 'Feb'})\n",
    "\n",
    "    # module subject mapping\n",
    "    code_module_mapping = {\n",
    "        'AAA': 'SocSci',\n",
    "        'BBB': 'SocSci',\n",
    "        'GGG': 'SocSci',\n",
    "        'CCC': 'Stem',\n",
    "        'DDD': 'Stem',\n",
    "        'EEE': 'Stem',\n",
    "        'FFF': 'Stem'\n",
    "    }\n",
    "    model_final['subject'] = model_final['code_module'].map(code_module_mapping)\n",
    "\n",
    "    # rename 'module_presentation_length' to 'course_length'\n",
    "    model_final.rename(columns={'module_presentation_length': 'course_length'}, inplace=True)\n",
    "\n",
    "    # combine 'code_module', 'code_presentation', and 'id_student' into 'mod_pres_stu'\n",
    "    model_final['mod_pres_stu'] = model_final['code_module'] + '-' + model_final['code_presentation'] + '-' + model_final['id_student'].astype(str)\n",
    "\n",
    "    # drop the separate columns 'code_module', 'code_presentation', and 'id_student'\n",
    "    model_final.drop(columns=['code_module', 'code_presentation', 'id_student'], inplace=True)\n",
    "\n",
    "    # move 'final_result' to the last column\n",
    "    final_result_column = model_final.pop('final_result')\n",
    "    model_final['final_result'] = final_result_column\n",
    "\n",
    "    # insert 'mod_pres_stu' as the first column\n",
    "    mod_pres_stu_column = model_final.pop('mod_pres_stu')\n",
    "    model_final.insert(0, 'mod_pres_stu', mod_pres_stu_column)\n",
    "\n",
    "    # drop columns: 'count_id_assessment', 'sum_score', 'sum_date', 'exp_sub_count', 'exp_sub_date_sum'\n",
    "    model_final.drop(columns=['count_id_assessment', 'sum_score', 'sum_date', 'exp_sub_count', 'exp_sub_date_sum'], inplace=True)\n",
    "\n",
    "    return model_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = tidy_up_model_final(model_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mod_pres_stu               20063\n",
       "gender                     20063\n",
       "region                     20063\n",
       "highest_education          20063\n",
       "imd_band                   20063\n",
       "age_band                   20063\n",
       "num_of_prev_attempts       20063\n",
       "studied_credits            20063\n",
       "disability                 20063\n",
       "course_length              20063\n",
       "date_registration          20063\n",
       "date_unregistration        20063\n",
       "status                     20063\n",
       "prop_submissions           20063\n",
       "avg_score                  20063\n",
       "submission_distance        20063\n",
       "stu_activity_count         20063\n",
       "stu_activity_type_count    20063\n",
       "stu_total_clicks           20063\n",
       "stu_days_active            20063\n",
       "mod_pres_vle_type_count    20063\n",
       "year                       20063\n",
       "month                      20063\n",
       "subject                    20063\n",
       "final_result               20063\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " mod_pres_stu               0\n",
      "gender                     0\n",
      "region                     0\n",
      "highest_education          0\n",
      "imd_band                   0\n",
      "age_band                   0\n",
      "num_of_prev_attempts       0\n",
      "studied_credits            0\n",
      "disability                 0\n",
      "course_length              0\n",
      "date_registration          0\n",
      "date_unregistration        0\n",
      "status                     0\n",
      "prop_submissions           0\n",
      "avg_score                  0\n",
      "submission_distance        0\n",
      "stu_activity_count         0\n",
      "stu_activity_type_count    0\n",
      "stu_total_clicks           0\n",
      "stu_days_active            0\n",
      "mod_pres_vle_type_count    0\n",
      "year                       0\n",
      "month                      0\n",
      "subject                    0\n",
      "final_result               0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_final.head()\n",
    "\n",
    "duplicate_students = model_final[model_final.duplicated(subset='mod_pres_stu', keep=False)]['mod_pres_stu'].unique()\n",
    "\n",
    "duplicate_students\n",
    "\n",
    "missing_values = model_final.isnull().sum()\n",
    "print(\"Missing values:\\n\", missing_values, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not working\n",
    "\n",
    "def process_data(zip_file, prediction_point):\n",
    "    # Load data from the zip file\n",
    "    registrations, courses, students, student_vle, vle, student_assessments, assessments = load_data(zip_file)\n",
    "\n",
    "    # Process student data\n",
    "    model_final = student_data(students, courses, registrations, prediction_point)\n",
    "\n",
    "    # Add assessments to model_final\n",
    "    model_final = add_assessments(model_final, student_assessments, assessments, courses, prediction_point)\n",
    "\n",
    "    # Add VLE data to model_final\n",
    "    model_final = add_vle_data(model_final, student_vle, vle, courses, prediction_point)\n",
    "\n",
    "    # Tidy up model_final\n",
    "    model_final = tidy_up_model_final(model_final)\n",
    "\n",
    "    return model_final\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'code_module'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\zoona\\OneDrive - UWE Bristol\\Modules\\ML_CW\\Machine_Learning_Analytics\\code\\data_v1_1.ipynb Cell 18\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/zoona/OneDrive%20-%20UWE%20Bristol/Modules/ML_CW/Machine_Learning_Analytics/code/data_v1_1.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_final \u001b[39m=\u001b[39m process_data(zipfile_ou, prediction_point)\n",
      "\u001b[1;32mc:\\Users\\zoona\\OneDrive - UWE Bristol\\Modules\\ML_CW\\Machine_Learning_Analytics\\code\\data_v1_1.ipynb Cell 18\u001b[0m in \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zoona/OneDrive%20-%20UWE%20Bristol/Modules/ML_CW/Machine_Learning_Analytics/code/data_v1_1.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model_final \u001b[39m=\u001b[39m student_data(students, courses, registrations, prediction_point)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zoona/OneDrive%20-%20UWE%20Bristol/Modules/ML_CW/Machine_Learning_Analytics/code/data_v1_1.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Add assessments to model_final\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/zoona/OneDrive%20-%20UWE%20Bristol/Modules/ML_CW/Machine_Learning_Analytics/code/data_v1_1.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model_final \u001b[39m=\u001b[39m add_assessments(model_final, student_assessments, assessments, courses, prediction_point)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zoona/OneDrive%20-%20UWE%20Bristol/Modules/ML_CW/Machine_Learning_Analytics/code/data_v1_1.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Add VLE data to model_final\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zoona/OneDrive%20-%20UWE%20Bristol/Modules/ML_CW/Machine_Learning_Analytics/code/data_v1_1.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m model_final \u001b[39m=\u001b[39m add_vle_data(model_final, student_vle, vle, courses, prediction_point)\n",
      "\u001b[1;32mc:\\Users\\zoona\\OneDrive - UWE Bristol\\Modules\\ML_CW\\Machine_Learning_Analytics\\code\\data_v1_1.ipynb Cell 18\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zoona/OneDrive%20-%20UWE%20Bristol/Modules/ML_CW/Machine_Learning_Analytics/code/data_v1_1.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m'''Returns updated model_final dataframe with student assessment data added:\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zoona/OneDrive%20-%20UWE%20Bristol/Modules/ML_CW/Machine_Learning_Analytics/code/data_v1_1.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zoona/OneDrive%20-%20UWE%20Bristol/Modules/ML_CW/Machine_Learning_Analytics/code/data_v1_1.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprediction_point is an integer representing the number of days from the start of the course for which you want to predict the outcome.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zoona/OneDrive%20-%20UWE%20Bristol/Modules/ML_CW/Machine_Learning_Analytics/code/data_v1_1.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m- calculate new features - average score, submission date distance, proportion of assessments submitted\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zoona/OneDrive%20-%20UWE%20Bristol/Modules/ML_CW/Machine_Learning_Analytics/code/data_v1_1.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zoona/OneDrive%20-%20UWE%20Bristol/Modules/ML_CW/Machine_Learning_Analytics/code/data_v1_1.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# merge 'assessments' and 'courses' on 'code_module' and 'code_presentation'\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/zoona/OneDrive%20-%20UWE%20Bristol/Modules/ML_CW/Machine_Learning_Analytics/code/data_v1_1.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m course_assess \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(assessments,courses, on\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mcode_module\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcode_presentation\u001b[39;49m\u001b[39m'\u001b[39;49m], how\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mleft\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zoona/OneDrive%20-%20UWE%20Bristol/Modules/ML_CW/Machine_Learning_Analytics/code/data_v1_1.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# fill in the missing 'date' values with course final week (as per literature)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zoona/OneDrive%20-%20UWE%20Bristol/Modules/ML_CW/Machine_Learning_Analytics/code/data_v1_1.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m value_to_fill \u001b[39m=\u001b[39m course_assess[\u001b[39m'\u001b[39m\u001b[39mmodule_presentation_length\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m3\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\zoona\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    109\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m--> 110\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[0;32m    111\u001b[0m         left,\n\u001b[0;32m    112\u001b[0m         right,\n\u001b[0;32m    113\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[0;32m    114\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m    115\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[0;32m    116\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[0;32m    117\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[0;32m    118\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[0;32m    119\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    120\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[0;32m    121\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[0;32m    122\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m    123\u001b[0m     )\n\u001b[0;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result(copy\u001b[39m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Users\\zoona\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:703\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cross \u001b[39m=\u001b[39m cross_col\n\u001b[0;32m    698\u001b[0m \u001b[39m# note this function has side effects\u001b[39;00m\n\u001b[0;32m    699\u001b[0m (\n\u001b[0;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_join_keys,\n\u001b[0;32m    701\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_join_keys,\n\u001b[0;32m    702\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjoin_names,\n\u001b[1;32m--> 703\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_merge_keys()\n\u001b[0;32m    705\u001b[0m \u001b[39m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[39m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m    707\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[1;32mc:\\Users\\zoona\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1179\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m \u001b[39mif\u001b[39;00m lk \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1176\u001b[0m     \u001b[39m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m     \u001b[39m#  the latter of which will raise\u001b[39;00m\n\u001b[0;32m   1178\u001b[0m     lk \u001b[39m=\u001b[39m cast(Hashable, lk)\n\u001b[1;32m-> 1179\u001b[0m     left_keys\u001b[39m.\u001b[39mappend(left\u001b[39m.\u001b[39;49m_get_label_or_level_values(lk))\n\u001b[0;32m   1180\u001b[0m     join_names\u001b[39m.\u001b[39mappend(lk)\n\u001b[0;32m   1181\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1182\u001b[0m     \u001b[39m# work-around for merge_asof(left_index=True)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zoona\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:1850\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1844\u001b[0m     values \u001b[39m=\u001b[39m (\n\u001b[0;32m   1845\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\n\u001b[0;32m   1846\u001b[0m         \u001b[39m.\u001b[39mget_level_values(key)  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m         \u001b[39m.\u001b[39m_values\n\u001b[0;32m   1848\u001b[0m     )\n\u001b[0;32m   1849\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1850\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[0;32m   1852\u001b[0m \u001b[39m# Check for duplicates\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'code_module'"
     ]
    }
   ],
   "source": [
    "# not working\n",
    "\n",
    "model_final = process_data(zipfile_ou, prediction_point)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add default for prediction point, ie. if none"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
